# minesweeper_with_RL

Solving minesweeper using reinforcement learning

The scripts test_minesweeper.py and plotting.py run the simulation and produce the results of our experiments.
The two input parameters are number of series and series size that determine how many times the experiment will run.

In test_minesweeper.py the win ratios and total reward of an agent playing minesweeper untrained,
and trained with Monte Carlo, Sarsa and Q-learning algorithms are compared after playing a set number of games (episodes).

The script plotting.py produces an experiment comparing the proportion of the board
opened by the agent after a set number of episodes using the 3 Reinforcement Learning Algorithms. 

The simulation of Minesweeper is obtained by the script minesweeper_simulation.py. 
It places num_mines number of bombs in random locations and calculates the number of adjacent bombs for each cell.
The actions and state representations are defined in this script.

The greedy and epsilon greedy policies are defined in states_minesweeper.py,
while rl_algorithm.py uses these to define the algorithms 
Sarsa, Q-learning and Monte Carlo for VFA. 

Traces are generated by simulation.py and the agents are trained in test_minesweeper.py 
